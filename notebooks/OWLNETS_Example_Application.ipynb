{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<img width='700' src=\"https://user-images.githubusercontent.com/8030363/108961534-b9a66980-7634-11eb-96e2-cc46589dcb8c.png\" style=\"vertical-align:middle\">\n",
    "\n",
    "## OWL-NETS Application - Example\n",
    "\n",
    "***\n",
    "\n",
    "**Author:** [TJCallahan](http://tiffanycallahan.com/)  \n",
    "**GitHub Repository:** [PheKnowLator](https://github.com/callahantiff/PheKnowLator/wiki)  \n",
    "**Wiki Page:** [OWL-NETS-2.0](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0)  \n",
    "**Release:** **[v2.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v2.0.0)**  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "`OWL-NETS` (NEtwork Transformation for Statistical learning) is a computational method that reversibly abstracts Web Ontology Language (OWL)-encoded biomedical knowledge into a more biologically meaningful network representation. OWL-NETS generates semantically rich knowledge graphs that contain heterogeneous nodes and edges and can be used for tasks that do not require OWL semantics. The algorithm consists of the following three steps:  \n",
    "1. Decode all OWL-encoded classes  \n",
    "2. Remove all triples that contain `subjects`, `predicates`, and/or `objects` that are needed to ensure OWL semantics, but are not biologically meaningful  \n",
    "3. Purify the decoded knowledge graph to match an input [knowledge graph construction approach](https://github.com/callahantiff/PheKnowLator/blob/master/resources/construction_approach/README.md) (i.e. `subclass` or `instance`) \n",
    "\n",
    "**Resources:**  \n",
    "> *Callahan TJ, Baumgartner Jr WA, Bada M, Stefanski AL, Tripodi I, White EK, Hunter LE. OWL-NETS: Transforming OWL representations for improved network inference. Pacific Symposium for Biocomputing 2018 Nov (pp. 133-144).*  \n",
    "*[Article Access](https://www.worldscientific.com/doi/abs/10.1142/9789813235533_0013)*\n",
    "\n",
    "<br>\n",
    " \n",
    "**Notebook Purpose:**  \n",
    "Provide an example of how to run the `OWL-NETS` independent of the [pkt_kg](https://pypi.org/project/pkt-kg/) knowledge graph construction work flow. In this notebook, we demonstrate how to apply `OWL-NETS` to the [`Human Phenotype Ontology`](https://hpo.jax.org/). \n",
    "\n",
    "*Generated Output:* \n",
    "- `OWLNETS_edgelist.txt` ➞ A tab-delimited file containing 3 columns (i.e. subject, predicate, object) each populated with a Universal Resource Identifier  \n",
    "- `OWLNETS_node_metadata.txt` ➞ A tab-delimited file containing 5 columns (i.e. node_id, node_label, node_synonym, node_dbxref, and namespace) for each node in the edge list     \n",
    "- `OWLNETS_relations.txt` ➞ A tab-delimited file containing 3 columns (i.e. relation_id, relation_label, and namespace) for each relation in the edge list  \n",
    "- `OWLNETS.nt` ➞ An `n-turtle` formatted file containing the `OWL-NETS` graph    \n",
    "- `OWLNETS_NetworkxMultiDiGraph.gpickle` ➞ A Networkx MukltiDiGraph representation of the `OWL-NETS` graph    \n",
    "- `OWLNETS_deocding_dict.pkl` ➞ A dictionary of important metadata from running `OWL-NETS`    \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assumptions:**   \n",
    "- `pkt_kg` has been downloaded (example code to download the library is shown below)  \n",
    "- A URL to the ontology you want to download OR ensure that the pre-downloaded ontology is located within your current working directory. An argument to set the working directory is provided below.  \n",
    "- [OWLTools]() if you have cloned the `pkt_kg` library from GitHub then you don't need to do anything, otherwise follow the directions on the `OWLTools` wiki.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    " \n",
    "_____\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Workflow  \n",
    "* [Set-Up Environment](#environment-setup)\n",
    "* [Download Ontology Data](#data-download)  \n",
    "* [Run OWL-NETS](#run-owlnets)  \n",
    "* [Finalize Output](#finalize-output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up Environment <a class=\"anchor\" id=\"environment-setup\"></a>\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Libraries\n",
    "\n",
    "If you have not cloned `pkt_kg` from GitHub, you need to install the latest version of the library from `PyPI`. TO do this, uncomment the second and third lines in the code chunk below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment and run to install any required modules from notebooks/requirements.txt\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if running a local version of pkt_kg, uncomment the code below\n",
    "# import sys\n",
    "# sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import os\n",
    "import pkt_kg as pkt\n",
    "import psutil\n",
    "import ray\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies\n",
    "\n",
    "If you have not cloned `pkt_kg` from GitHub, you need to install the latest version of [OWLTools](https://github.com/owlcollab/owltools) from GitHub. Run the code chunk below to do this (only if you have not cloned `pkt_kg` from GitHub). Then, set the location where you downloaded `OWLTools` to in the \"Define GLobal Variables\" chunk below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move into pkt_kg/libs/ directory\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../pkt_kg/libs')\n",
    "\n",
    "# download owltools and update permissions\n",
    "os.system('wget https://github.com/callahantiff/PheKnowLator/raw/master/pkt_kg/libs/owltools')\n",
    "os.system('chmod +x owltools')\n",
    "\n",
    "# move back to roject working directory\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '../owlnets_output'\n",
    "\n",
    "# make sure working directlry exists\n",
    "if not os.path.exists(working_dir): os.mkdir(working_dir)\n",
    "    \n",
    "# set path to owltools location   \n",
    "owltools_location = '../pkt_kg/libs/owltools'\n",
    "\n",
    "# cpus\n",
    "cpus = psutil.cpu_count(logical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Ontology Data Download <a class=\"anchor\" id=\"data-download\"></a>\n",
    "_____\n",
    "\n",
    "Downloads the [Human Phenotype Ontology](http://purl.obolibrary.org/obo/hp.owl) (`HPO`) file using the PURL URL (i.e. `http://purl.obolibrary.org/obo/hp.owl`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the url for the ontology you want to download\n",
    "url = 'http://purl.obolibrary.org/obo/hp.owl'\n",
    "\n",
    "# download ontology data\n",
    "filename = working_dir + '/' + url.split('/')[-1][:-4] + '_with_imports.owl'\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    command = \"{} {} --merge-import-closure -o {}\"\n",
    "    os.system(command.format(owltools_location, url, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load downloaded ontology into memory\n",
    "print('Loading Ontology Data Downloaded From: {}'.format(url))\n",
    "graph = Graph().parse(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Ontology Metadata\n",
    "\n",
    "Prior to running `OWL-NETS` we want to extract metadata for the nodes and edges. For this project we download labels for both nodes and relations. In addition to downloading labels for nodes, we also download synonyms and any database dross-references (dbxRefs). Metadata for nodes and relations are stored in the `entity_metadata` dictionary under the keys `nodes` and `relations`. An example of what the dictionary looks like is shown below:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "entity_metadata = {\n",
    "    'nodes': {\n",
    "        'http://purl.obolibrary.org/obo/HP_0001052': {\n",
    "            'labels': 'Nevus flammeus',\n",
    "            'synonmys': 'nevus simplex|port-wine stain',\n",
    "            'dxbrefs': 'snomedct_us:416377005|snomedct_us:254211001|msh:d019339|umls:c0235752|meddra:10067193',\n",
    "            'namespace': 'HP'\n",
    "        }...},\n",
    "    'relations': {\n",
    "        'http://purl.obolibrary.org/obo/RO_0002231': {\n",
    "            'labels': 'has start location',\n",
    "            'namespace': 'RO'\n",
    "        }...}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty node metadata dictionary\n",
    "entity_metadata = {'nodes': {}, 'relations': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extract Node Metadata*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_classes = pkt.utils.gets_ontology_classes(graph)\n",
    "ont_labels = {str(x[0]): str(x[2]) for x in list(graph.triples((None, RDFS.label, None)))}\n",
    "ont_synonyms = pkt.utils.gets_ontology_class_synonyms(graph)\n",
    "ont_dbxrefs = pkt.utils.gets_ontology_class_dbxrefs(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the metadata to the master metadata dictionary\n",
    "for cls in tqdm(ont_classes):\n",
    "    # get class metadata - synonyms and dbxrefs\n",
    "    syns = '|'.join([k for k, v in ont_synonyms[0].items() if v == str(cls)])\n",
    "    dbxrefs = '|'.join([k for k, v in ont_dbxrefs[0].items() if v == str(cls)])\n",
    "    \n",
    "    # extract metadata\n",
    "    if '_' in str(cls): namespace = re.findall(r'^(.*?)(?=\\W|_)', str(cls).split('/')[-1])[0].upper()\n",
    "    else: namespace = str(cls).split('/')[2]\n",
    "    \n",
    "    # update dict\n",
    "    entity_metadata['nodes'][str(cls)] = {\n",
    "        'label': ont_labels[str(cls)] if str(cls) in ont_labels.keys() else 'None',\n",
    "        'synonyms': syns if syns != '' else 'None',\n",
    "        'dbxrefs': dbxrefs if dbxrefs != '' else 'None',\n",
    "        'namespace': namespace \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extract Relation Metadata*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_objects = pkt.utils.gets_object_properties(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the metadata to the master metadata dictionary\n",
    "for obj in tqdm(ont_objects):\n",
    "    # get object label\n",
    "    label_hits = list(graph.objects(obj, RDFS.label))\n",
    "    label = str(label_hits[0]) if len(label_hits) > 0 else 'None'\n",
    "    \n",
    "    # get object namespace\n",
    "    if 'obo' in str(obj) and len(str(obj).split('/')) > 5: \n",
    "        namespace = str(obj).split('/')[-2].upper()\n",
    "    else:\n",
    "        if '_' in str(obj): namespace = re.findall(r'^(.*?)(?=\\W|_)', str(obj).split('/')[-1])[0].upper()\n",
    "        else: namespace = str(obj).split('/')[2]\n",
    "    \n",
    "    # update dict\n",
    "    entity_metadata['relations'][str(obj)] = {'label': label, 'namespace': namespace}\n",
    "\n",
    "# add RDF:type and RDFS:subclassOf\n",
    "entity_metadata['relations']['http://www.w3.org/2000/01/rdf-schema#subClassOf'] = {'label': 'subClassOf', 'namespace': 'www.w3.org'}\n",
    "entity_metadata['relations']['https://www.w3.org/1999/02/22-rdf-syntax-ns#type'] = {'label': 'type', 'namespace': 'www.w3.org'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Run OWL-NETS <a class=\"anchor\" id=\"run-owlnets\"></a>\n",
    "_____\n",
    "\n",
    "Run the `OWL-NETS` algorithm. We pass a standard set of input parameters, ones which are unlikely to change for any application, unless you are interested in obtain a knowledge-purified version of the original input knowledge graph (i.e. `kg_construct_approach`). To learn more about this option, please see the project wiki page ([here](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0)). To help make it easier to understand what `OWL-NETS` does, the program is broken down into it's component steps below. If you want to run the full program, you can do the following instead:\n",
    "\n",
    "``` python\n",
    "# initialize owlnets class\n",
    "owlnets = pkt.OWLNETS(graph=graph,\n",
    "                      write_location=write_dir,\n",
    "                      filename=filename,\n",
    "                      kg_construct_approach=None,\n",
    "                      owl_tools=owltools_location)\n",
    "# run algorithm\n",
    "owlnets_res = owlnets.runs_owlnets(cpus)\n",
    "ray.shutdown()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stats for original graph before running OWL-NETS\n",
    "pkt.utils.derives_graph_statistics(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize owlnets class\n",
    "owlnets = pkt.OwlNets(graph=graph,\n",
    "                      write_location=working_dir + '/',\n",
    "                      filename=filename.split('/')[-1],\n",
    "                      kg_construct_approach=None,\n",
    "                      owl_tools=owltools_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Disjointness Axioms\n",
    "\n",
    "The first step is to remove all `owl:disjointWith` axioms from the graph. These axioms are removed because they are a form of negation in the graph and cannot currently be presented in another way while also being biologically menaingful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove disjointness\n",
    "owlnets.removes_disjoint_with_axioms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Semantic Triples\n",
    "\n",
    "Creates a filtered knowledge graph, such that only nodes that are owl:Class/owl:Individual connected via a `owl:ObjectProperty` and not an `owl:AnnotationProperty`. For example:\n",
    "\n",
    "REMOVE - edges needed to support owl semantics (not biologically meaningful):  \n",
    "- subject: `http://purl.obolibrary.org/obo/CLO_0037294`   \n",
    "- predicate: `owl:AnnotationProperty `   \n",
    "- object: `rdf:about=\"http://purl.obolibrary.org/obo/CLO_0037294\"`\n",
    "\n",
    "KEEP - biologically meaningful edges:\n",
    "- subject: `http://purl.obolibrary.org/obo/CHEBI_16130`\n",
    "- predicate: `http://purl.obolibrary.org/obo/RO_0002606`\n",
    "- object: `http://purl.obolibrary.org/obo/HP_0000832`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove triples used only to support semantics\n",
    "cleaned_graph = owlnets.removes_edges_with_owl_semantics()\n",
    "filtered_triple_count = len(owlnets.owl_nets_dict['filtered_triples'])\n",
    "\n",
    "print('removed {} triples that were not biologically meaninginful'.format(filtered_triple_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode OWL Classes\n",
    "The algorithm used to decode all OWL classes is shown below, which works to unwind class that are constructed from `owl:Restrictions` and the OWL constructors `owl:UnionOf` and `owl:intersectionOf`. Please see the [wiki](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0) for more details.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/8030363/110973128-120a8600-831a-11eb-9064-9bf02608da73.png\" width=\"450\" height=\"600\" align=\"left\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather list of owl:class and owl:axiom entities\n",
    "owl_classes = list(pkt.utils.gets_ontology_classes(owlnets.graph))\n",
    "owl_axioms = []\n",
    "for x in tqdm(set(owlnets.graph.subjects(RDF.type, OWL.Axiom))):\n",
    "    src = set(owlnets.graph.objects(list(owlnets.graph.objects(x, OWL.annotatedSource))[0], RDF.type))\n",
    "    tgt = set(owlnets.graph.objects(list(owlnets.graph.objects(x, OWL.annotatedTarget))[0], RDF.type))\n",
    "    if OWL.Class in src and OWL.Class in tgt: owl_axioms += [x]\n",
    "    elif (OWL.Class in src and len(tgt) == 0) or (OWL.Class in tgt and len(src) == 0): owl_axioms += [x]\n",
    "    else: pass\n",
    "node_list = list(set(owl_classes) | set(owl_axioms))\n",
    "\n",
    "print('There are:\\n-{} OWL:Class objects\\n-{} OWL:Axiom Objects'. format(len(owl_classes), len(owl_axioms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode owl semantics\n",
    "decoded_graph = owlnets.cleans_owl_encoded_entities(node_list)\n",
    "decoded_graph = owlnets.gets_owlnets_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update graph to get all cleaned egdes\n",
    "owlnets.graph = cleaned_graph + decoded_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print owlnets results\n",
    "str1 = 'Decoded {} owl-encoded classes and axioms. Note the following:\\nPartially processed {} cardinality ' \\\n",
    "               'elements\\nRemoved {} owl:disjointWith axioms\\nIgnored:\\n  -{} misc classes;\\n  -{} classes constructed with ' \\\n",
    "               'owl:complementOf;\\n  -{} classes containing negation (e.g. pr#lacks_part, cl#has_not_completed)\\n' \\\n",
    "               'Filtering removed {} semantic support triples'\n",
    "stats_str = str1.format(\n",
    "    len(owlnets.owl_nets_dict['decoded_entities'].keys()), len(owlnets.owl_nets_dict['cardinality'].keys()),\n",
    "    len(owlnets.owl_nets_dict['disjointWith']), len(owlnets.owl_nets_dict['misc'].keys()),\n",
    "    len(owlnets.owl_nets_dict['complementOf'].keys()), len(owlnets.owl_nets_dict['negation'].keys()),\n",
    "    len(owlnets.owl_nets_dict['filtered_triples']))\n",
    "print('=' * 80 + '\\n' + stats_str + '\\n' + '=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Graph Single Connected Component**  \n",
    "Depending on the source ontology that you apply `OWL-NETS` to, it's possible that the decoded graph may contain more than a single connected component. If you'd like to ensure that the graph contains only a single connected component, run the code chunk below.\n",
    "\n",
    "*How Does it Work?*  \n",
    "<u>Goal</u>: Ensure the resulting graph is connected without reducing the biological meaningfulness of the resulting graph  \n",
    "\n",
    "<u>Solution</u>: Enforce that the highest ancestor node for each node in the graph is `rdfs:subClassOf` of a specific ontology class. The node used can have a significant impact on the resulting graph so the selected node should be done with caution     \n",
    "- `BFO` entity ([BFO_0000001](http://purl.obolibrary.org/obo/BFO_0000001)) is the default choice    \n",
    "- If you prefer a different ontology concept be used, update the code chunk below by replacing the `http://purl.obolibrary.org/obo/BFO_0000001` with your preferred URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run line below if you want to ensure resulting graph contains \n",
    "common_ancestor = 'http://purl.obolibrary.org/obo/BFO_0000001'\n",
    "owlnets.graph = owlnets.makes_graph_connected(owlnets.graph, common_ancestor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write OWL-NETS Results\n",
    "\n",
    "The following output files are generated after running the `OWL-NETS` algorithm:\n",
    "- `OWLNETS.nt` ➞ An `n-turtle` formatted file containing the `OWL-NETS` graph    \n",
    "- `OWLNETS_NetworkxMultiDiGraph.gpickle` ➞ A Networkx MukltiDiGraph representation of the `OWL-NETS` graph    \n",
    "- `OWLNETS_deocding_dict.pkl` ➞ A dictionary of important metadata from running `OWL-NETS`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and write owl-nets results\n",
    "owlnets.write_location = working_dir\n",
    "owlnets.write_out_results(owlnets.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Output <a class=\"anchor\" id=\"finalize-output\"></a>\n",
    "_____\n",
    "\n",
    "This section generates the following additional output files from the `OWL-NETS` decoded knowledge graph:  \n",
    "- `OWLNETS_edgelist.txt` ➞ A tab-delimited file containing 3 columns (i.e. subject, predicate, object) each populated with a Universal Resource Identifier  \n",
    "- `OWLNETS_node_metadata.txt` ➞ A tab-delimited file containing 5 columns (i.e. node_id, node_label, node_synonym, node_dbxref, and namespace) for each node in the edge list     \n",
    "- `OWLNETS_relations.txt` ➞ A tab-delimited file containing 3 columns (i.e. relation_id, relation_label, and namespace) for each relation in the edge list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge List\n",
    "Write out the `OWL-NETS` results as a `tab-delimited` text file. An example of the output is shown in the table below: \n",
    "\n",
    "subject | predicate | object\n",
    ":--: | :--: | :--:\n",
    "http://purl.obolibrary.org/obo/UBERON_0003060 | http://purl.obolibrary.org/obo/RO_0002202 | http://purl.obolibrary.org/obo/UBERON_0005721\n",
    "http://purl.obolibrary.org/obo/HP_0009402 | http://purl.obolibrary.org/obo/RO_0000086 | http://purl.obolibrary.org/obo/PATO_0001512\n",
    "http://purl.obolibrary.org/obo/CHEBI_35804 | http://www.w3.org/2000/01/rdf-schema#subClassOf | http://purl.obolibrary.org/obo/CHEBI_133748\n",
    "http://purl.obolibrary.org/obo/HP_0100717 | http://www.w3.org/2000/01/rdf-schema#subClassOf | http://purl.obolibrary.org/obo/HP_0011061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename for writing edge list\n",
    "edge_list_filename = working_dir + '/' + 'OWLNETS_edgelist.txt'\n",
    "\n",
    "# write out results\n",
    "with open(edge_list_filename, 'w') as out:\n",
    "    out.write('subject' + '\\t' + 'predicate' + '\\t' + 'object' + '\\n')\n",
    "    for row in tqdm(owlnets.graph):\n",
    "        out.write(str(row[0]) + '\\t' + str(row[1]) + '\\t' + str(row[2]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Metadata\n",
    "Write out metadata for all of the `OWL-NETS` nodes as a `tab-delimited` text file. The file contains the following columns:\n",
    "- <u>node_id</u>: A node identifier in the form of a resolvable URI.  \n",
    "- <u>node_namespace</u>: A string contain the namespace for the ontology.  \n",
    "- <u>node_label</u>: A string containing the node's label (If no value provided then 'None')\n",
    "- <u>node_synonyms</u>: A `|`-delimited string of node synonyms (If no value provided then 'None')\n",
    "- <u>node_dbxrefs</u>: A `|`-delimited string of node database cross-references (If no value provided then 'None')\n",
    "\n",
    "<br>\n",
    "\n",
    "An example row of data is shown in the table below:\n",
    "\n",
    "node_id | node_namespace | node_label | node_synonyms | node_dbxrefs\n",
    ":--: | :--: | :--: | :--: | :--:\n",
    "http://purl.obolibrary.org/obo/GO_0097164 | GO | ammonium ion metabolic process | ammonium ion metabolism\\|ammonium metabolic process | None\n",
    "http://purl.obolibrary.org/obo/CHEBI_36242 | CHEBI | 3-(4-hydroxyphenyl)pyruvate | hpp\\|3-(p-hydroxyphenyl)pyruvate\\|4-hydroxyphenylpyruvate\\|3-(4-hydroxyphenyl)pyruvate\\|3-(4-hydroxyphenyl)-2-oxopropanoate\\|p-hydroxyphenylpyruvate | um-bbd_compid:c0235\\|reaxys:3950858\\|beilstein:3950858\\|pmid:11948155\\|pmid:14593448\n",
    "http://purl.obolibrary.org/obo/HP_0009293 | HP | Broad middle phalanx of the 4th finger | broad middle bone of the 4th finger | umls:c4024463\n",
    "http://purl.obolibrary.org/obo/HP_0009643 | HP | Bullet-shaped distal phalanx of the thumb | bullet-shaped outermost bone of the thumb | umls:c4024260\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename for writing node metadata\n",
    "node_metadata_filename = working_dir + '/' + 'OWLNETS_node_metadata.txt'\n",
    "\n",
    "# get all unique nodes in OWL-NETS graph\n",
    "nodes = set([x for y in [[str(x[0]), str(x[2])] for x in owlnets.graph] for x in y])\n",
    "\n",
    "# write out results\n",
    "with open(node_metadata_filename, 'w') as out:\n",
    "    out.write('node_id' + '\\t' + 'node_namespace' + '\\t' + 'node_label' + '\\t' + 'node_synonyms' + '\\t' + 'node_dbxrefs' + '\\n')\n",
    "    for x in tqdm(nodes):\n",
    "        if x in entity_metadata['nodes'].keys():\n",
    "            namespace = entity_metadata['nodes'][x]['namespace']\n",
    "            labels = entity_metadata['nodes'][x]['label']\n",
    "            synonyms = entity_metadata['nodes'][x]['synonyms']\n",
    "            dbxrefs = entity_metadata['nodes'][x]['dbxrefs']\n",
    "            out.write(x + '\\t' + namespace + '\\t' + labels + '\\t' + synonyms + '\\t' + dbxrefs + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relations\n",
    "\n",
    "Write out metadata for all of the `OWL-NETS` relations as a `tab-delimited` text file. The file contains the following columns:\n",
    "- <u>relation_id</u>: A relation identifier in the form of a resolvable URI.  \n",
    "- <u>relation_namespace</u>: A string contain the namespace for the ontology.  \n",
    "- <u>relation_label</u>: A string containing the relation's label (If no value provided then 'None')\n",
    "\n",
    "<br>\n",
    "\n",
    "An example row of data is shown in the table below:\n",
    "\n",
    "relation_id | relation_namespace | relation_label\n",
    ":--: | :--: | :--:\n",
    "http://purl.obolibrary.org/obo/chebi#is_tautomer_of | CHEBI | is tautomer of\n",
    "http://purl.obolibrary.org/obo/uberon/core#indirectly_supplies | UBERON | indirectly_supplies\n",
    "http://purl.obolibrary.org/obo/cl#has_not_completed | CL | has_not_completed\n",
    "http://purl.obolibrary.org/obo/RO_0002380 | RO | branching_part_of\n",
    "http://purl.obolibrary.org/obo/pato#has_relative_magnitude | PATO | has_relative_magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename for writing relation metadata\n",
    "relation_filename = working_dir + '/' + 'OWLNETS_relations.txt'\n",
    "\n",
    "# get all unique nodes in OWL-NETS graph\n",
    "relations = set([str(x[1]) for x in owlnets.graph])\n",
    "\n",
    "# write out results\n",
    "with open(relation_filename, 'w') as out:\n",
    "    out.write('relation_id' + '\\t' + 'relation_namespace' + '\\t' + 'relation_label' + '\\n')\n",
    "    for x in tqdm(relations):\n",
    "        namespace = entity_metadata['relations'][x]['namespace']\n",
    "        labels = entity_metadata['relations'][x]['label']\n",
    "        out.write(x + '\\t' + namespace + '\\t' + labels + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
