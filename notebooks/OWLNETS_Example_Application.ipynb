{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<img width='700' src=\"https://user-images.githubusercontent.com/8030363/108961534-b9a66980-7634-11eb-96e2-cc46589dcb8c.png\" style=\"vertical-align:middle\">\n",
    "\n",
    "## OWL-NETS Application - Example\n",
    "\n",
    "***\n",
    "\n",
    "**Author:** [TJCallahan](http://tiffanycallahan.com/)  \n",
    "**GitHub Repository:** [PheKnowLator](https://github.com/callahantiff/PheKnowLator/wiki)  \n",
    "**Wiki Page:** [OWL-NETS-2.0](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0)  \n",
    "**Release:** **[v2.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v2.0.0)**  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "`OWL-NETS` (NEtwork Transformation for Statistical learning) is a computational method that reversibly abstracts Web Ontology Language (OWL)-encoded biomedical knowledge into a more biologically meaningful network representation. OWL-NETS generates semantically rich knowledge graphs that contain heterogeneous nodes and edges and can be used for tasks that do not require OWL semantics. The algorithm consists of the following three steps:  \n",
    "1. Decode all OWL-encoded classes  \n",
    "2. Remove all triples that contain `subjects`, `predicates`, and/or `objects` that are needed to ensure OWL semantics, but are not biologically meaningful  \n",
    "3. Purify the decoded knowledge graph to match an input [knowledge graph construction approach](https://github.com/callahantiff/PheKnowLator/blob/master/resources/construction_approach/README.md) (i.e. `subclass` or `instance`) \n",
    "\n",
    "**Resources:**  \n",
    "> *Callahan TJ, Baumgartner Jr WA, Bada M, Stefanski AL, Tripodi I, White EK, Hunter LE. OWL-NETS: Transforming OWL representations for improved network inference. Pacific Symposium for Biocomputing 2018 Nov (pp. 133-144).*  \n",
    "*[Article Access](https://www.worldscientific.com/doi/abs/10.1142/9789813235533_0013)*\n",
    "\n",
    "<br>\n",
    " \n",
    "**Notebook Purpose:**  \n",
    "Provide an example of how to run the `OWL-NETS` independent of the [pkt_kg](https://pypi.org/project/pkt-kg/) knowledge graph construction work flow. In this notebook, we demonstrate how to apply `OWL-NETS` to the [`Human Phenotype Ontology`](https://hpo.jax.org/). \n",
    "\n",
    "*Generated Output:* \n",
    "- `OWLNETS_edgelist.txt` ➞ A tab-delimited file containing 3 columns (i.e. subject, predicate, object) each populated with a Universal Resource Identifier  \n",
    "- `OWLNETS_node_metadata.txt` ➞ A tab-delimited file containing 6 columns (i.e. node_id, node_namespace, node_label, node_definition, node_synonyms, node_dbxrefs) for each node in the edge list     \n",
    "- `OWLNETS_relations.txt` ➞ A tab-delimited file containing 4 columns (i.e. relation_id, relation_namespace, relation_label, relation_definition) for each relation in the edge list  \n",
    "- `OWLNETS.nt` ➞ An `n-turtle`-formatted file containing the `OWL-NETS` graph    \n",
    "- `OWLNETS_NetworkxMultiDiGraph.gpickle` ➞ A Networkx MukltiDiGraph representation of the `OWL-NETS` graph    \n",
    "- `OWLNETS_deocding_dict.pkl` ➞ A dictionary of important metadata from running `OWL-NETS`    \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assumptions:**   \n",
    "- `pkt_kg` has been downloaded (example code to download the library is shown below)  \n",
    "- A URL to the ontology you want to download OR ensure that the pre-downloaded ontology is located within your current working directory. An argument to set the working directory is provided below.  \n",
    "- [OWLTools]() if you have cloned the `pkt_kg` library from GitHub then you don't need to do anything, otherwise follow the directions on the `OWLTools` wiki.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    " \n",
    "_____\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Workflow  \n",
    "* [Set-Up Environment](#environment-setup)\n",
    "* [Download Ontology Data](#data-download)  \n",
    "* [Run OWL-NETS](#run-owlnets)  \n",
    "* [Finalize Output](#finalize-output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up Environment <a class=\"anchor\" id=\"environment-setup\"></a>\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Satisfy Program Dependencies\n",
    "\n",
    "This code chunk will make sure needed directories, files, and external libraries are obtained and placed in the correct and expected locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment and run to install any required modules from notebooks/requirements.txt\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if running a local version of pkt_kg (i.e., not running the PyPI version), uncomment the code below\n",
    "# import sys\n",
    "# sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Set-up Logging Directory*  \n",
    "This code chunk will make sure that the directory (`builds/logs`) and file (`builds/logs/logging.ini`) needed to ensure the script is properly logged is downloaded. By default, logs are written to the `builds/logs` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load set-up modules\n",
    "import os\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure directory for logging exists\n",
    "builds_dir = '../builds'; full_log_dir = builds_dir + '/logs'\n",
    "if not os.path.exists(full_log_dir):\n",
    "    os.makedirs(full_log_dir)\n",
    "\n",
    "# check for logging file in logs directory\n",
    "if not os.path.exists(builds_dir + '/logging.ini'):\n",
    "    urlretrieve('https://raw.githubusercontent.com/callahantiff/PheKnowLator/master/builds/logging.ini',\n",
    "                builds_dir + '/logging.ini')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*External Libraries*  \n",
    "If you have not cloned `pkt_kg` from GitHub, you need to install the latest version of [OWLTools](https://github.com/owlcollab/owltools) from GitHub. Run the code chunk below to do this (only if you have not cloned `pkt_kg` from GitHub). Then, set the location where you downloaded `OWLTools` to in the \"Define Global Variables\" chunk below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move into pkt_kg/libs/ directory\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../pkt_kg/libs')\n",
    "\n",
    "# download owltools and update permissions\n",
    "if not os.path.exists('owltools'):\n",
    "    os.system('wget https://github.com/callahantiff/PheKnowLator/raw/master/pkt_kg/libs/owltools')\n",
    "    os.system('chmod +x owltools')\n",
    "\n",
    "# move back to roject working directory\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Libraries\n",
    "\n",
    "If you have not cloned `pkt_kg` from GitHub, you need to install the latest version of the library from `PyPI`. To do this, uncomment the second and third lines in the code chunk below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import pkt_kg as pkt\n",
    "import psutil\n",
    "import ray\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '../owlnets_output'\n",
    "\n",
    "# make sure the working directory exists\n",
    "if not os.path.exists(working_dir): os.mkdir(working_dir)\n",
    "    \n",
    "# set path to owltools location   \n",
    "owltools_location = '../pkt_kg/libs/owltools'\n",
    "\n",
    "# specify the number of cpus\n",
    "cpus = psutil.cpu_count(logical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Ontology Data Download <a class=\"anchor\" id=\"data-download\"></a>\n",
    "_____\n",
    "\n",
    "Downloads the [Human Phenotype Ontology](http://purl.obolibrary.org/obo/hp.owl) (`HPO`) file using the PURL URL (i.e. `http://purl.obolibrary.org/obo/hp.owl`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the url for the ontology you want to download\n",
    "url = 'http://purl.obolibrary.org/obo/hp.owl'\n",
    "\n",
    "# download ontology data\n",
    "filename = working_dir + '/' + url.split('/')[-1][:-4] + '_with_imports.owl'\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    command = \"{} {} --merge-import-closure -o {}\"\n",
    "    os.system(command.format(owltools_location, url, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load downloaded ontology into memory\n",
    "print('Loading Ontology Data Downloaded From: {}'.format(url))\n",
    "graph = Graph().parse(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Ontology Metadata\n",
    "\n",
    "Prior to running `OWL-NETS` we want to extract metadata for the nodes and relations. For this project we download labels and definitions for both nodes and relations. In addition to downloading labels for nodes, we also download synonyms and any database cross-references (dbxRefs). Metadata for nodes and relations are stored in the `entity_metadata` dictionary under the keys `nodes` and `relations`. An example of what the dictionary looks like is shown below:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "entity_metadata = {\n",
    "    'nodes': {\n",
    "        'http://purl.obolibrary.org/obo/HP_0001052': {\n",
    "            'labels': 'Nevus flammeus',\n",
    "            'definitions': 'A congenital vascular malformation consisting of superficial and deep dilated capillaries in the skin which produce a reddish to purplish discolouration of the skin.'\n",
    "            'synonmys': 'nevus simplex|port-wine stain',\n",
    "            'dxbrefs': 'snomedct_us:416377005|snomedct_us:254211001|msh:d019339|umls:c0235752|meddra:10067193',\n",
    "            'namespace': 'HP'\n",
    "        }...},\n",
    "    'relations': {\n",
    "        'http://purl.obolibrary.org/obo/RO_0002231': {\n",
    "            'labels': 'has start location',\n",
    "            'definitions': \"X 'has starts location' y if and only if there exists some process z such that x 'starts with' z and z 'occurs in' y\"\n",
    "            'namespace': 'RO'\n",
    "        }...}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty node metadata dictionary\n",
    "entity_metadata = {'nodes': {}, 'relations': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extract Node Metadata*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_classes = pkt.utils.gets_ontology_classes(graph)\n",
    "ont_labels = {str(x[0]): str(x[2]) for x in list(graph.triples((None, RDFS.label, None))) if '@' not in pkt.utils.n3(x[2]) or '@en' in pkt.utils.n3(x[2])}\n",
    "ont_synonyms = pkt.utils.gets_ontology_class_synonyms(graph)\n",
    "ont_dbxrefs = pkt.utils.gets_ontology_class_dbxrefs(graph)\n",
    "ont_defs = pkt.utils.gets_ontology_definitions(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the metadata to the master metadata dictionary\n",
    "for cls in tqdm(ont_classes):\n",
    "    # get class metadata - synonyms and dbxrefs\n",
    "    syns = '|'.join([k for k, v in ont_synonyms[0].items() if str(cls) in v])\n",
    "    dbxrefs = '|'.join([k for k, v in ont_dbxrefs[0].items() if str(cls) in v])\n",
    "    \n",
    "    # extract metadata\n",
    "    if '_' in str(cls): namespace = re.findall(r'^(.*?)(?=\\W|_)', str(cls).split('/')[-1])[0].upper()\n",
    "    else: namespace = str(cls).split('/')[2]\n",
    "    \n",
    "    # update dict\n",
    "    entity_metadata['nodes'][str(cls)] = {\n",
    "        'label': re.sub('\\s\\s+', ' ', ont_labels[str(cls)].replace('\\n', ' ')) if str(cls) in ont_labels.keys() else 'None',\n",
    "        'synonyms': re.sub('\\s\\s+', ' ', syns.replace('\\n', ' ')) if syns != '' else 'None',\n",
    "        'dbxrefs': re.sub('\\s\\s+', ' ', dbxrefs.replace('\\n', ' ')) if dbxrefs != '' else 'None',\n",
    "        'namespace': re.sub('\\s\\s+', ' ', namespace.replace('\\n', ' ')), \n",
    "        'definitions': re.sub('\\s\\s+', ' ', str(ont_defs[cls]).replace('\\n', ' ')) if cls in ont_defs.keys() else 'None',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extract Relation Metadata*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ont_objects = pkt.utils.gets_object_properties(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in tqdm(ont_objects):\n",
    "    # get object label\n",
    "    label_hits = [x for x in graph.objects(obj, RDFS.label) if '@' not in pkt.utils.n3(x) or '@en' in pkt.utils.n3(x)]\n",
    "    label = str(label_hits[0]) if len(label_hits) > 0 else 'None'\n",
    "    \n",
    "    # get object namespace\n",
    "    if 'obo' in str(obj) and len(str(obj).split('/')) > 5: \n",
    "        namespace = str(obj).split('/')[-2].upper()\n",
    "    else:\n",
    "        if '_' in str(obj): namespace = re.findall(r'^(.*?)(?=\\W|_)', str(obj).split('/')[-1])[0].upper()\n",
    "        else: namespace = str(obj).split('/')[2]\n",
    "    \n",
    "    # handle definition information\n",
    "    def_str = str(ont_defs[obj]) if obj in ont_defs.keys() else 'None'\n",
    "    \n",
    "    # update dict\n",
    "    entity_metadata['relations'][str(obj)] = {\n",
    "        'label': re.sub('\\s\\s+', ' ', label.replace('\\n', ' ')),\n",
    "        'namespace': re.sub('\\s\\s+', ' ', namespace.replace('\\n', ' ')),\n",
    "        'definitions': re.sub('\\s\\s+', ' ', def_str.replace('\\n', ' '))}\n",
    "\n",
    "# add RDF:type and RDFS:subclassOf\n",
    "entity_metadata['relations']['http://www.w3.org/2000/01/rdf-schema#subClassOf'] = {'label': 'subClassOf', 'definitions': 'None', 'namespace': 'www.w3.org'}\n",
    "entity_metadata['relations']['http://www.w3.org/1999/02/22-rdf-syntax-ns#type'] = {'label': 'type', 'definitions': 'None', 'namespace': 'www.w3.org'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Statistics Before OWL-NETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stats for original graph before running OWL-NETS\n",
    "pkt.utils.derives_graph_statistics(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Run OWL-NETS <a class=\"anchor\" id=\"run-owlnets\"></a>\n",
    "_____\n",
    "\n",
    "Run the `OWL-NETS` algorithm. We pass a standard set of input parameters, ones which are unlikely to change for any application, unless you are interested in obtaining a knowledge-purified version of the original input knowledge graph (i.e. `kg_construct_approach`). To learn more about this option, please see the project wiki page ([here](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0)). \n",
    "\n",
    "**Parameter Explanation:**  \n",
    "- `graph`: An RDFLib object or a list of RDFLib Graph objects.  \n",
    "- `write_location`: A file path used for writing knowledge graph data (e.g. \"resources/\".\n",
    "- `filename`: A string containing the filename for the full knowledge graph (e.g. \"/hpo_owlnets\").   \n",
    "- `kg_construct_approach`: A string containing the type of construction approach used to build the knowledge graph.  \n",
    "- `owl_tools`: A string pointing to the location of the owl tools library.  \n",
    "- `top_level`: A list of ontology namespaces that should not appear in any <u>subject</u> or <u>object</u> in the clean graph (default list: [['ISO'](https://www.iso.org/home.html), ['SUMO'](https://www.ontologyportal.org/), ['BFO'](https://basic-formal-ontology.org/)]).  \n",
    "- `support`: A list of ontology namespaces that should not appear in any <u>subject</u>, <u>object</u>, or <u>relation</u> in the clean graph (default list: [['IAO'](http://www.obofoundry.org/ontology/iao.html), ['SWO'](http://www.obofoundry.org/ontology/swo.html), ['OBI'](http://obi-ontology.org/), ['UBPROP']()]).  \n",
    "- `relations`: A list of ontology namespaces that should not appear in any <u>subject</u> or <u>object</u> in the clean graph (default list [['RO'](http://www.obofoundry.org/ontology/ro.html)]).  \n",
    "\n",
    "\n",
    "To help make it easier to understand what `OWL-NETS` does, the program is broken down into its component steps. If you want to run the full program, you can do the following instead (default parameters are shown):\n",
    "\n",
    "``` python\n",
    "# initialize owlnets class\n",
    "owlnets = pkt.OWLNETS(graph=graph,\n",
    "                      write_location=write_dir,\n",
    "                      filename=filename,\n",
    "                      kg_construct_approach=None,\n",
    "                      owl_tools=owltools_location,\n",
    "                      top_level=['ISO', 'SUMO', 'BFO'],\n",
    "                      support=['IAO', 'SWO', 'OBI', 'UBPROP'],\n",
    "                      relations=['RO'])\n",
    "# run algorithm\n",
    "owlnets_res = owlnets.runs_owlnets(cpus)\n",
    "ray.shutdown()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize owlnets class\n",
    "owlnets = pkt.OwlNets(graph=graph,\n",
    "                      write_location=working_dir + '/',\n",
    "                      filename=filename.split('/')[-1],\n",
    "                      kg_construct_approach=None,\n",
    "                      owl_tools=owltools_location,\n",
    "                      top_level=['ISO', 'SUMO', 'BFO'],\n",
    "                      support=['IAO', 'SWO', 'OBI', 'UBPROP'],\n",
    "                      relations=['RO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Disjointness Axioms\n",
    "\n",
    "The first step is to remove all `owl:disjointWith` axioms from the graph. These axioms are removed because they are a form of negation in the graph and cannot currently be presented in another way while also being biologically meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove disjointness\n",
    "owlnets.removes_disjoint_with_axioms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Semantic Triples\n",
    "\n",
    "Creates a filtered knowledge graph, such that only nodes that are `owl:Class`/`owl:NamedIndividual` connected via a `owl:ObjectProperty` and not an `owl:AnnotationProperty`. For example:\n",
    "\n",
    "REMOVE - edges needed to support owl semantics (not biologically meaningful):  \n",
    "- subject: `http://purl.obolibrary.org/obo/CLO_0037294`   \n",
    "- predicate: `owl:AnnotationProperty `   \n",
    "- object: `rdf:about=\"http://purl.obolibrary.org/obo/CLO_0037294\"`\n",
    "\n",
    "KEEP - biologically meaningful edges:\n",
    "- subject: `http://purl.obolibrary.org/obo/CHEBI_16130`\n",
    "- predicate: `http://purl.obolibrary.org/obo/RO_0002606`\n",
    "- object: `http://purl.obolibrary.org/obo/HP_0000832`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove triples used only to support semantics\n",
    "cleaned_graph = owlnets.removes_edges_with_owl_semantics()\n",
    "filtered_triple_count = len(owlnets.owl_nets_dict['filtered_triples'])\n",
    "\n",
    "print('removed {} triples that were not biologically meaningful'.format(filtered_triple_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode OWL Classes\n",
    "The algorithm used to decode all OWL classes is shown below, which works to unwind class that are constructed from `owl:Restrictions` and the OWL constructors `owl:UnionOf` and `owl:intersectionOf`. Please see the [wiki](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0) for more details.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/8030363/110973128-120a8600-831a-11eb-9064-9bf02608da73.png\" width=\"450\" height=\"600\" align=\"left\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "*Gather list of `owl:Class` and `owl:Axiom` Entities*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl_classes = list(pkt.utils.gets_ontology_classes(owlnets.graph))\n",
    "owl_axioms = []\n",
    "for x in tqdm(set(owlnets.graph.subjects(RDF.type, OWL.Axiom))):\n",
    "    src = set(owlnets.graph.objects(list(owlnets.graph.objects(x, OWL.annotatedSource))[0], RDF.type))\n",
    "    tgt = set(owlnets.graph.objects(list(owlnets.graph.objects(x, OWL.annotatedTarget))[0], RDF.type))\n",
    "    if OWL.Class in src and OWL.Class in tgt: owl_axioms += [x]\n",
    "    elif (OWL.Class in src and len(tgt) == 0) or (OWL.Class in tgt and len(src) == 0): owl_axioms += [x]\n",
    "    else: pass\n",
    "node_list = list(set(owl_classes) | set(owl_axioms))\n",
    "\n",
    "print('There are:\\n-{} OWL:Class objects\\n-{} OWL:Axiom Objects'. format(len(owl_classes), len(owl_axioms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decode OWL Semantics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_graph = owlnets.cleans_owl_encoded_entities(node_list)\n",
    "decoded_graph = owlnets.gets_owlnets_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Update Graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owlnets.graph = cleaned_graph + decoded_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Print OWL-NETS Results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'Decoded {} owl-encoded classes and axioms. Note the following:\\nPartially processed {} cardinality ' \\\n",
    "               'elements\\nRemoved {} owl:disjointWith axioms\\n\\nIgnored:\\n  -{} misc classes;\\n  -{} classes constructed with ' \\\n",
    "               'owl:complementOf;\\n  -{} classes containing negation (e.g. pr#lacks_part, cl#has_not_completed)\\n' \\\n",
    "               '\\nFiltering removed {} semantic support triples'\n",
    "stats_str = str1.format(\n",
    "    len(owlnets.owl_nets_dict['decoded_entities'].keys()), len(owlnets.owl_nets_dict['cardinality'].keys()),\n",
    "    len(owlnets.owl_nets_dict['disjointWith']), len(owlnets.owl_nets_dict['misc'].keys()),\n",
    "    len(owlnets.owl_nets_dict['complementOf'].keys()), len(owlnets.owl_nets_dict['negation'].keys()),\n",
    "    len(owlnets.owl_nets_dict['filtered_triples']))\n",
    "print('=' * 80 + '\\n' + stats_str + '\\n' + '=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Make Graph Single Connected Component**  \n",
    "Depending on the source ontology that you apply `OWL-NETS` to, it's possible that the decoded graph may contain more than a single connected component. If you'd like to ensure that the graph contains only a single connected component, run the code chunk below.\n",
    "\n",
    "*How Does it Work?*  \n",
    "<u>Goal</u>: Ensure the resulting graph is connected without reducing the biological meaningfulness of the resulting graph  \n",
    "\n",
    "<u>Solution</u>: Enforce that the highest ancestor node for each node in the graph is `rdfs:subClassOf` of a specific ontology class. The node used can have a significant impact on the resulting graph so the selected node should be done with caution     \n",
    "- `BFO` entity ([BFO_0000001](http://purl.obolibrary.org/obo/BFO_0000001)) is the default choice    \n",
    "- If you prefer a different ontology concept be used, update the code chunk below by replacing the `http://purl.obolibrary.org/obo/BFO_0000001` with your preferred URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run line below if you want to ensure resulting graph contains \n",
    "common_ancestor = 'http://purl.obolibrary.org/obo/BFO_0000001'\n",
    "owlnets.graph = owlnets.makes_graph_connected(owlnets.graph, common_ancestor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Write OWL-NETS Results\n",
    "\n",
    "The following output files are generated after running the `OWL-NETS` algorithm:\n",
    "- `OWLNETS.nt` ➞ An `n-turtle` formatted file containing the `OWL-NETS` graph    \n",
    "- `OWLNETS_NetworkxMultiDiGraph.gpickle` ➞ A Networkx MukltiDiGraph representation of the `OWL-NETS` graph    \n",
    "- `OWLNETS_deocding_dict.pkl` ➞ A dictionary of important metadata from running `OWL-NETS`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and write owl-nets results\n",
    "owlnets.write_location = working_dir\n",
    "owlnets.write_out_results(owlnets.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Finalize Output <a class=\"anchor\" id=\"finalize-output\"></a>\n",
    "_____\n",
    "\n",
    "This section generates the following additional output files from the `OWL-NETS` decoded knowledge graph:  \n",
    "- `OWLNETS_edgelist.txt` ➞ A tab-delimited file containing 3 columns (i.e. subject, predicate, object) each populated with a Universal Resource Identifier  \n",
    "- `OWLNETS_node_metadata.txt` ➞ A tab-delimited file containing 5 columns (i.e. node_id, node_label, node_synonym, node_dbxref, and namespace) for each node in the edge list     \n",
    "- `OWLNETS_relations.txt` ➞ A tab-delimited file containing 3 columns (i.e. relation_id, relation_label, and namespace) for each relation in the edge list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge List\n",
    "Write out the `OWL-NETS` results as a `tab-delimited` text file. An example of the output is shown in the table below: \n",
    "\n",
    "subject | predicate | object\n",
    ":--: | :--: | :--:\n",
    "http://purl.obolibrary.org/obo/UBERON_0003060 | http://purl.obolibrary.org/obo/RO_0002202 | http://purl.obolibrary.org/obo/UBERON_0005721\n",
    "http://purl.obolibrary.org/obo/HP_0009402 | http://purl.obolibrary.org/obo/RO_0000086 | http://purl.obolibrary.org/obo/PATO_0001512\n",
    "http://purl.obolibrary.org/obo/CHEBI_35804 | http://www.w3.org/2000/01/rdf-schema#subClassOf | http://purl.obolibrary.org/obo/CHEBI_133748\n",
    "http://purl.obolibrary.org/obo/HP_0100717 | http://www.w3.org/2000/01/rdf-schema#subClassOf | http://purl.obolibrary.org/obo/HP_0011061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename for writing edge list\n",
    "edge_list_filename = working_dir + '/' + 'OWLNETS_edgelist.txt'\n",
    "\n",
    "# write out results\n",
    "with open(edge_list_filename, 'w') as out:\n",
    "    out.write('subject' + '\\t' + 'predicate' + '\\t' + 'object' + '\\n')\n",
    "    for row in tqdm(owlnets.graph):\n",
    "        out.write(str(row[0]) + '\\t' + str(row[1]) + '\\t' + str(row[2]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Metadata\n",
    "Write out metadata for all of the `OWL-NETS` nodes as a `tab-delimited` text file. The file contains the following columns:\n",
    "- <u>node_id</u>: A node identifier in the form of a resolvable URI.  \n",
    "- <u>node_namespace</u>: A string contain the namespace for the ontology.  \n",
    "- <u>node_label</u>: A string containing the node's label (If no value provided then 'None')\n",
    "- <u>node_definition</u>: A string containing the node's definition (If no value provided then 'None')\n",
    "- <u>node_synonyms</u>: A `|`-delimited string of node synonyms (If no value provided then 'None')\n",
    "- <u>node_dbxrefs</u>: A `|`-delimited string of node database cross-references (If no value provided then 'None')\n",
    "\n",
    "<br>\n",
    "\n",
    "An example row of data is shown in the table below:\n",
    "\n",
    "node_id | node_namespace | node_label | node_definition | node_synonyms | node_dbxrefs\n",
    ":--: | :--: | :--: | :--: | :--: | :--:\n",
    "http://purl.obolibrary.org/obo/GO_0097164 | GO | ammonium ion metabolic process | The chemical reactions and pathways involving the ammonium ion. [database_cross_reference: GOC:tb][database_cross_reference: GOC:dhl][database_cross_reference: PMID:14671018] | ammonium ion metabolism\\|ammonium metabolic process | None\n",
    "http://purl.obolibrary.org/obo/CHEBI_36242 | CHEBI | 3-(4-hydroxyphenyl)pyruvate | A 2-oxo monocarboxylic acid anion obtained by removal of a proton from the carboxylic acid group of 3-(4-hydroxyphenyl)pyruvic acid. | hpp\\|3-(p-hydroxyphenyl)pyruvate\\|4-hydroxyphenylpyruvate\\|3-(4-hydroxyphenyl)pyruvate\\|3-(4-hydroxyphenyl)-2-oxopropanoate\\|p-hydroxyphenylpyruvate | um-bbd_compid:c0235\\|reaxys:3950858\\|beilstein:3950858\\|pmid:11948155\\|pmid:14593448\n",
    "http://purl.obolibrary.org/obo/HP_0009293 | HP | Broad middle phalanx of the 4th finger | Increased width of the middle phalanx of the 4th finger. | broad middle bone of the 4th finger | umls:c4024463\n",
    "http://purl.obolibrary.org/obo/HP_0009643 | HP | Bullet-shaped distal phalanx of the thumb | Bullet-shaped phalanx refers to a short and wide phalanx that tapers distally. Bullet-shaped phalanges lack the normal diaphyseal constriction. This term is used if the distal phalanx of the thumb is affected.| bullet-shaped outermost bone of the thumb | umls:c4024260\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename for writing node metadata\n",
    "node_metadata_filename = working_dir + '/' + 'OWLNETS_node_metadata.txt'\n",
    "\n",
    "# get all unique nodes in OWL-NETS graph\n",
    "nodes = set([x for y in [[str(x[0]), str(x[2])] for x in owlnets.graph] for x in y])\n",
    "\n",
    "# write out results\n",
    "with open(node_metadata_filename, 'w') as out:\n",
    "    out.write('node_id' + '\\t' + 'node_namespace' + '\\t' + 'node_label' + '\\t' + 'node_definition' + '\\t' + 'node_synonyms' + '\\t' + 'node_dbxrefs' + '\\n')\n",
    "    for x in tqdm(nodes):\n",
    "        if x in entity_metadata['nodes'].keys():\n",
    "            namespace = entity_metadata['nodes'][x]['namespace']\n",
    "            labels = entity_metadata['nodes'][x]['label']\n",
    "            definitions = entity_metadata['nodes'][x]['definitions']\n",
    "            synonyms = entity_metadata['nodes'][x]['synonyms']\n",
    "            dbxrefs = entity_metadata['nodes'][x]['dbxrefs']\n",
    "            out.write(x + '\\t' + namespace + '\\t' + labels + '\\t' + definitions + '\\t' + synonyms + '\\t' + dbxrefs + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relations\n",
    "\n",
    "Write out metadata for all of the `OWL-NETS` relations as a `tab-delimited` text file. The file contains the following columns:\n",
    "- <u>relation_id</u>: A relation identifier in the form of a resolvable URI.  \n",
    "- <u>relation_namespace</u>: A string contain the namespace for the ontology.  \n",
    "- <u>relation_label</u>: A string containing the relation's label (If no value provided then 'None')  \n",
    "- <u>relation_definition</u>: A string containing the relation's definition (If no value provided then 'None')\n",
    "\n",
    "<br>\n",
    "\n",
    "An example row of data is shown in the table below:\n",
    "\n",
    "relation_id | relation_namespace | relation_label | relation_definition\n",
    ":--: | :--: | :--: | :--:\n",
    "http://purl.obolibrary.org/obo/uberon/core#indirectly_supplies | UBERON | indirectly_supplies | a indirectly_supplies s iff a has a branch and the branch supplies or indirectly supplies s\n",
    "http://purl.obolibrary.org/obo/RO_0002380 | RO | branching_part_of | X is a branching part of y if and only if x is part of y and x is connected directly or indirectly to the main stem of y\n",
    "http://purl.obolibrary.org/obo/OBI_0000417 | OBI | achieves_planned_objective | This relation obtains between a planned process and a objective specification when the criteria specified in the objective specification are met at the end of the planned process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename for writing relation metadata\n",
    "relation_filename = working_dir + '/' + 'OWLNETS_relations.txt'\n",
    "\n",
    "# get all unique nodes in OWL-NETS graph\n",
    "relations = set([str(x[1]) for x in owlnets.graph])\n",
    "\n",
    "# write out results\n",
    "with open(relation_filename, 'w') as out:\n",
    "    out.write('relation_id' + '\\t' + 'relation_namespace' + '\\t' + 'relation_label' + '\\t' + 'relation_definition' + '\\n')\n",
    "    for x in tqdm(relations):\n",
    "        namespace = entity_metadata['relations'][x]['namespace']\n",
    "        labels = entity_metadata['relations'][x]['label']\n",
    "        definitions = entity_metadata['relations'][x]['definitions']\n",
    "        out.write(x + '\\t' + namespace + '\\t' + labels + '\\t' + definitions + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
