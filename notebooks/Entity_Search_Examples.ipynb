{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<img width='700' src=\"https://user-images.githubusercontent.com/8030363/108961534-b9a66980-7634-11eb-96e2-cc46589dcb8c.png\" style=\"vertical-align:middle\">\n",
    "\n",
    "## Knowledge Graph Entity Search Examples\n",
    "\n",
    "***\n",
    "\n",
    "**Author:** [TJCallahan](http://tiffanycallahan.com/)  \n",
    "**GitHub Repository:** [PheKnowLator](https://github.com/callahantiff/PheKnowLator/wiki)  \n",
    "**Wiki Page:** [OWL-NETS-2.0](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0)  \n",
    "**Release:** **[v3.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v3.0.0)**  \n",
    "  \n",
    "<br> \n",
    "\n",
    "### Purpose  \n",
    "The goal of this notebook is to explore different ways to examine relationships between entities in a PheKnowLator knowledge graph.\n",
    "\n",
    "#### PheKnowLator Knowledge Graph Build  \n",
    "This notebook was built using a `v3.0.2` OWL-NETS-abstracted subclass-based build with inverse relations, which is publicly available and can be downloaded using the following links:  \n",
    "- [PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle](https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle)  \n",
    "- [PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt](https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***  \n",
    "## Set-Up Environment \n",
    "***  \n",
    "\n",
    "### Dependencies: [pkt_kg](https://pypi.org/project/pkt-kg/), [networkx](https://pypi.org/project/networkx/), [rdflib](https://pypi.org/project/rdflib/)\n",
    "\n",
    "To prepare for the tutorial we need to make sure that the all needed libraries are downloaded and imported. If you don't already have `pkt_kg`, `rdflib`, and `networkx` installed, you can extend the code chunk below to include any libraries that you need to download. In addition to downloading needed libraries, you will also need to download the specific version of each knowledge graph that you want to analyze. Each data source is briefly described in the next section.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment and run to install any required modules from notebooks/requirements.txt\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -r ../../notebooks/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if running a local version of pkt_kg, uncomment the code below\n",
    "# import sys\n",
    "# sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import json\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "from pkt_kg.utils import *\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import RDFS\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "# create namespace for OBO ontologies\n",
    "obo = Namespace('http://purl.obolibrary.org/obo/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph \n",
    "The initial exploration will be performed using a `v3.0.2` OWL-NETS-abstracted subclass-based build with inverse relations, which is publicly available and can be downloaded using the following links:  \n",
    "- [PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle](https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle)  \n",
    "- [PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt](https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook will create a temporary directory\n",
    "# write_location = '../releases/Columbia_Collaboration/tara_anand/data/'\n",
    "write_location = '../temp_directory/'\n",
    "if not os.path.exists(write_location):\n",
    "    os.mkdir(write_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data to the data directory\n",
    "data_urls = [\n",
    "    'https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle',\n",
    "    'https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt',\n",
    "    'https://www.dropbox.com/s/ev0ea6v6fu70fbl/entity_metadata_dict.pkl?dl=1'\n",
    "]\n",
    "\n",
    "for url in data_urls:\n",
    "    file_name = url.split('/')[-1] if 'entity_metadata_dict.pkl' not in url else re.sub(r'\\?.*', '', url.split('/')[-1])\n",
    "    if not os.path.exists(write_location + file_name):\n",
    "        data_downloader(url, write_location, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions \n",
    "Create helper functions that are needed to process node data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     28,
     54,
     80,
     105
    ]
   },
   "outputs": [],
   "source": [
    "def nx_ancestor_search(kg: nx.multidigraph.MultiDiGraph, nodes: List, prefix: str, anc_list: Optional[List]=None) -> Union[Callable, List]:\n",
    "    \"\"\"Returns all ancestors nodes reachable through a direct edge. The returned list is ordered by senority.\n",
    "    \n",
    "    Args:\n",
    "        kg: A networkx MultiDiGraph object.\n",
    "        nodes: A list of RDFLib URIRef objects or None.\n",
    "        prefix: A string containing an ontology prefix (e..g., MONDO).\n",
    "        anc_list: A list that is empty or that contains RDFLib URIRef objects.\n",
    "        \n",
    "    Returns:\n",
    "        anc_list: A list of period-delimited strings, where each string represents a path \n",
    "    \"\"\"\n",
    "    \n",
    "    ancestor_list = [] if anc_list is None else anc_list\n",
    "    \n",
    "    if len(nodes) == 0: return ancestor_list\n",
    "    else:\n",
    "        node = nodes.pop()\n",
    "        node_list = list(kg.neighbors(node))\n",
    "        neighborhood = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node, n)).keys()]\n",
    "                          for i in j] for n in node_list] for a in b]\n",
    "        ancestors = [x[1] for x in neighborhood if (prefix in str(x[1]) and x[0] == RDFS.subClassOf)]\n",
    "        if len(ancestors) > 0:\n",
    "            ancestor_list += [[str(x) for x in ancestors]]\n",
    "            nodes += ancestors\n",
    "        return nx_ancestor_search(kg, nodes, prefix, ancestor_list)\n",
    "    \n",
    "    \n",
    "def processes_ancestor_path_list(path_list: List, node_metadata: Dict) -> Dict:\n",
    "    \"\"\"Processes a nested list of ancestor paths into a single unique list.\n",
    "    \n",
    "    Args:\n",
    "        path_list: A nested list of ontology URLs, where each list represents a set of ancestors.\n",
    "        node_metadata: A dictionary \n",
    "    \n",
    "    Returns:\n",
    "        ancestors: A nested list where each inner list contains ontology identifier strings\n",
    "    \"\"\"\n",
    "    \n",
    "    anc_dict = dict()\n",
    "    \n",
    "    for path in path_list:\n",
    "        for x in path:\n",
    "            idx = max([i for i, j in enumerate(path_list) if x in j])\n",
    "            if str(idx) in anc_dict.keys(): anc_dict[str(idx)] |= {x}\n",
    "            else: anc_dict[str(idx)] = {x}\n",
    "\n",
    "    # reorder and format keys\n",
    "    ancestors = [['{} ({})'.format(node_data_dict[str(x)]['label'], x) for x in anc_dict[str(k)]]\n",
    "                 for k in sorted([int(x) for x in anc_dict.keys()])]\n",
    "    \n",
    "    return ancestors\n",
    "\n",
    "\n",
    "def formats_node_information(neighborhood: List, metadata_dict: Dict, verbose: bool=False) -> None:\n",
    "    \"\"\"Processes neighborhood results.\n",
    "    \n",
    "    Args:\n",
    "        neighborhood: A nested list of strings, where each string contains a node identifier.\n",
    "        metadata_dict: node_metadata: A nested dictionary containing node attributes.\n",
    "        verbose: A bool indicating whether or not node and edge metadata should be printed.\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    for e, o in neighborhood:\n",
    "        spe = '\\n' if neighborhood.index([e, o]) == 0 else '\\n\\n'\n",
    "        s, s_label = str(node[0]).split('/')[-1], metadata_dict[str(node[0])]['label']\n",
    "        e_label = metadata_dict[str(e)]['label']\n",
    "        o, o_label, o_def = str(o).split('/')[-1], metadata_dict[str(o)]['label'], metadata_dict[str(o)]['description']\n",
    "        if verbose:\n",
    "            if o_def != 'None': print(spe + '>>> {} ({}) - {} - {} ({})\\n{} Definition: {}'.format(s_label, s, e_label, o_label, o, o, o_def))\n",
    "            else: print(spe + '>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "        else: print('>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "    \n",
    "    return None\n",
    "    \n",
    "\n",
    "def metadata_formatter(s: str, o: str, metadata_dict: Dict) -> None:\n",
    "    \"\"\"Function looks up edge-level metadata and prints it.\n",
    "    \n",
    "    Args:\n",
    "        s: A string containing the identifier for the subject node of a predicate or triple.\n",
    "        o: A string containing the identifier for the object node of a predicate or triple.\n",
    "        metadata_dict: A nested dictionary containing node and edge-level metadata.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s + '-reactome_' if 'R-HSA' in s else s\n",
    "    o = o + '-reactome_' if 'R-HSA' in o else o\n",
    "    \n",
    "    if s + '-' + o in metadata_dict['edges'].keys():\n",
    "        print('\\nEdge Evidence'); print(json.dumps(metadata_dict['edges'][s + '-' + o], indent=4))\n",
    "    elif o + '-' + s in metadata_dict['edges'].keys():\n",
    "         print('\\nEdge Evidence'); print(json.dumps(metadata_dict['edges'][o + '-' + s], indent=4))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def formats_path_information(kg: nx.multidigraph.MultiDiGraph, paths: List, path_type: str, metadata_func: Callable, metadata_dict: Dict, node_metadata: Dict, verbose: bool=False, rand: bool=False, sample_size: int=10) -> None:\n",
    "    \"\"\"Processes shortest and simple path results.\n",
    "    \n",
    "    Args:\n",
    "        kg: A networkx MultiDiGraph object.\n",
    "        paths: A nested list of strings, where each string contains an an entity identifier.\n",
    "        path_type: A string, either 'simple' or 'shortest' that indicates the types of paths to process.\n",
    "        metadata_func: A function that processes edge metadata.\n",
    "        metadata_dict: A nested dictionary containing node and edge-level metadata. \n",
    "        node_metadata: A nested dictionary containing node attributes.\n",
    "        verbose: A bool indicating whether or not node and edge metadata should be printed.\n",
    "        rand: A bool indicating whether or not to draw random samples from the path.\n",
    "        sample_size: An integer used when rand is True to specify the size of the random sample to draw.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    if path_type == 'shortest': \n",
    "        for i in range(0, len(paths[0]) - 1):\n",
    "            s = paths[0][i]; o = paths[0][i + 1]\n",
    "            edges = kg.get_edge_data(*(s, o)).keys()\n",
    "            for e in edges:\n",
    "                spe = '\\n' if list(edges).index(e) == 0 else '\\n\\n\\n'\n",
    "                s, s_label = str(s).split('/')[-1], node_metadata[str(s)]['label']\n",
    "                e_label = node_metadata[str(e)]['label']\n",
    "                o, o_label, o_def = str(o).split('/')[-1], node_metadata[str(o)]['label'], node_metadata[str(o)]['description']\n",
    "                if verbose:\n",
    "                    if o_def != 'None': print(spe + '>>> {} ({}) - {} - {} ({})\\n\\n{} Definition: {}'.format(s_label, s, e_label, o_label, o, o, o_def))\n",
    "                    else: print(spe + '>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "                    metadata_func(s, o, metadata_dict)\n",
    "                else: print('>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "    else:\n",
    "        if rand: paths = random.sample(paths, sample_size)\n",
    "        for path in paths:\n",
    "            print('*' * 100)\n",
    "            for i in range(0, len(path) - 1):\n",
    "                spe = '\\n' if i == 0 else '\\n\\n\\n'\n",
    "                s = path[i]; o = path[i + 1]; edges = kg.get_edge_data(*(s, o))\n",
    "                try: edges.keys()\n",
    "                except AttributeError: edges = kg.get_edge_data(*(o, s))\n",
    "                for e in edges.keys():\n",
    "                    s, s_label = str(s).split('/')[-1], node_metadata[str(s)]['label']\n",
    "                    e_label = node_metadata[str(e)]['label']\n",
    "                    o, o_label, o_def = str(o).split('/')[-1], node_metadata[str(o)]['label'], node_metadata[str(o)]['description']\n",
    "                    if verbose:\n",
    "                        if o_def != 'None': print(spe + '>>> {} ({}) - {} - {} ({})\\n\\n{} Definition: {}'.format(s_label, s, e_label, o_label, o, o, o_def))\n",
    "                        else: print(spe + '>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "                        metadata_func(s, o, metadata_dict)\n",
    "                    else: print('>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "            print('*' * 100); print('\\n')\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## Loading Data\n",
    "***\n",
    "\n",
    "___\n",
    "\n",
    "The knowledge graph will be loaded as a `networkx` MultiDiGraph object and the node labels will be read in and converted to a dictionary to enable easy access to node labels and other relevant metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The knowledge graph contains 780753 nodes and 7787308 edges\n"
     ]
    }
   ],
   "source": [
    "# load the knowledge graph\n",
    "kg = nx.read_gpickle(write_location + data_urls[0].split('/')[-1])\n",
    "print('The knowledge graph contains {} nodes and {} edges'.format(len(kg.nodes()), len(kg.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert multidigraph to undirected graph -- needed to run some of the algorithms\n",
    "undirected_kg = kg.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_type</th>\n",
       "      <th>integer_id</th>\n",
       "      <th>entity_uri</th>\n",
       "      <th>label</th>\n",
       "      <th>description/definition</th>\n",
       "      <th>synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NODES</td>\n",
       "      <td>684158</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/snp/rs864622148</td>\n",
       "      <td>NM_000051.4(ATM):c.5887G&gt;A (p.Asp1963Asn)</td>\n",
       "      <td>This variant is a germline single nucleotide v...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NODES</td>\n",
       "      <td>668197</td>\n",
       "      <td>https://uswest.ensembl.org/Homo_sapiens/Transc...</td>\n",
       "      <td>CUL9-211</td>\n",
       "      <td>Transcript CUL9-211 is classified as type 'non...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NODES</td>\n",
       "      <td>769680</td>\n",
       "      <td>http://purl.obolibrary.org/obo/CHEBI_116891</td>\n",
       "      <td>3-(3-methylphenyl)-2-sulfanylidene-1H-benzofur...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NODES</td>\n",
       "      <td>381659</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/snp/rs61741688</td>\n",
       "      <td>NM_001272071.2(AP1S2):c.288T&gt;C (p.Ser96=)</td>\n",
       "      <td>This variant is a germline single nucleotide v...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NODES</td>\n",
       "      <td>720533</td>\n",
       "      <td>http://purl.obolibrary.org/obo/PR_Q9Y2I7-3</td>\n",
       "      <td>1-phosphatidylinositol 3-phosphate 5-kinase is...</td>\n",
       "      <td>A 1-phosphatidylinositol 3-phosphate 5-kinase ...</td>\n",
       "      <td>hPIKFYVE/iso:h3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_type  integer_id                                         entity_uri  \\\n",
       "0       NODES      684158       https://www.ncbi.nlm.nih.gov/snp/rs864622148   \n",
       "1       NODES      668197  https://uswest.ensembl.org/Homo_sapiens/Transc...   \n",
       "2       NODES      769680        http://purl.obolibrary.org/obo/CHEBI_116891   \n",
       "3       NODES      381659        https://www.ncbi.nlm.nih.gov/snp/rs61741688   \n",
       "4       NODES      720533         http://purl.obolibrary.org/obo/PR_Q9Y2I7-3   \n",
       "\n",
       "                                               label  \\\n",
       "0          NM_000051.4(ATM):c.5887G>A (p.Asp1963Asn)   \n",
       "1                                           CUL9-211   \n",
       "2  3-(3-methylphenyl)-2-sulfanylidene-1H-benzofur...   \n",
       "3          NM_001272071.2(AP1S2):c.288T>C (p.Ser96=)   \n",
       "4  1-phosphatidylinositol 3-phosphate 5-kinase is...   \n",
       "\n",
       "                              description/definition          synonym  \n",
       "0  This variant is a germline single nucleotide v...             None  \n",
       "1  Transcript CUL9-211 is classified as type 'non...             None  \n",
       "2                                               None             None  \n",
       "3  This variant is a germline single nucleotide v...             None  \n",
       "4  A 1-phosphatidylinositol 3-phosphate 5-kinase ...  hPIKFYVE/iso:h3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in node metadata\n",
    "node_data = pd.read_csv(write_location + data_urls[1].split('/')[-1], header=0, sep=r\"\\t\", encoding=\"utf8\", engine='python', quoting=3)\n",
    "# remove angle brackets\n",
    "node_data['entity_uri'] = node_data['entity_uri'].str.strip('<>')\n",
    "\n",
    "node_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94990af9fe146f7ae8e5ea649c19504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=781049.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove angle brackets\n",
    "node_data['entity_uri'] = node_data['entity_uri'].str.strip('<>')\n",
    "\n",
    "# convert node data to dictionary\n",
    "node_data_dict = dict()\n",
    "for idx, row in tqdm(node_data.iterrows(), total=node_data.shape[0]):\n",
    "    node_data_dict[row['entity_uri']] = {\n",
    "        'label': row['label'],\n",
    "        'description': row['description/definition'],\n",
    "        'synonym': row['synonym']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is temporary while the next release is being formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../releases/Columbia_Collaboration/tara_anand/data/entity_metadata_dict.pkl?dl=1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5aa907383b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_location\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmax_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m31\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mbytes_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../releases/Columbia_Collaboration/tara_anand/data/entity_metadata_dict.pkl?dl=1'"
     ]
    }
   ],
   "source": [
    "# load metadata\n",
    "filepath = write_location + data_urls[2].split('/')[-1]\n",
    "max_bytes = 2**31 - 1; input_size = os.path.getsize(filepath); bytes_in = bytearray(0)\n",
    "with open(filepath, 'rb') as f_in:\n",
    "    for _ in range(0, input_size, max_bytes):\n",
    "        bytes_in += f_in.read(max_bytes)\n",
    "metadata_dict = pickle.loads(bytes_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## Knowledge-based Characterization\n",
    "***\n",
    "____\n",
    "\n",
    "The goal is to use the knowledge graph to explore what we know about specific concepts as well as what we can say about pairs of concepts. Additional details are presented by comparison below:\n",
    "\n",
    "#### [Node-Level](#node-level)\n",
    " - <u>Node Ancestry</u>: Identify all ancestors for each node up to the root.\n",
    " - <u>Node Neighborhood</u>: Returns all nodes reachable from a node of interest via a single directed edge.   \n",
    "\n",
    "\n",
    "#### [Path-Level](#path-level)\n",
    "  - <u>All Shortest Paths</u>: Returns the shortest simple path, if there are multiple paths of the same length then they are all returned.\n",
    "  - <u>All Simple Paths</u>: A simple path is a path with no repeated nodes. These nodes are identified using a modified depth-first search. Given that there are a lot of these, the initial output is limited to a random draw of 10 paths of length 10 from the first 100 derived paths.\n",
    "  \n",
    "For all comparisons, the full edge is returned along with all relevant node and edge metadata provided by each data source.\n",
    "\n",
    "  ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node-Level Characterization  <a class=\"anchor\" id=\"node-level\"></a>\n",
    "\n",
    "This section characterizes the following concepts:\n",
    "- [benazepril (`CHEBI_3011`)](#chebi1)  \n",
    "- [hydrochlorothiazide (`CHEBI_5778`)](#chebi2)  \n",
    "- [Acute Myocardial Infarction (`MONDO_0004781`)](#mondo1)  \n",
    "- [Myocardial infarction (`HP_0001658`)](#hpo1)\n",
    "\n",
    "*Note*. All output is presented twice for each analysis, the first without any metadata/evidence and the second time, with metadata. This is done to facilitate readability.\n",
    "\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### benazepril (`CHEBI_3011`) <a class=\"anchor\" id=\"chebi1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'CHEBI'; node = [obo.CHEBI_3011]\n",
    "path_list = nx_ancestor_search(kg, node.copy(), prefix)\n",
    "chebi3011_ancestors = processes_ancestor_path_list(path_list, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(chebi3011_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in chebi3011_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "chebi3011_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(chebi3011_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(chebi3011_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**hydrochlorothiazide (`CHEBI_5778`)** <a class=\"anchor\" id=\"chebi2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'CHEBI'; node = [obo.CHEBI_5778]\n",
    "path_list = nx_ancestor_search(kg, node.copy(), prefix)\n",
    "chebi5778_ancestors = processes_ancestor_path_list(path_list, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(chebi5778_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in chebi5778_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "chebi5778_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(chebi5778_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(chebi5778_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Myocardial Infarction (`MONDO_0005068`)** <a class=\"anchor\" id=\"mondo1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'MONDO'; node = [obo.MONDO_0005068]\n",
    "path_list = nx_ancestor_search(kg, node.copy(), prefix)\n",
    "mondo0005068_ancestors = processes_ancestor_path_list(path_list, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(mondo0005068_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in mondo0005068_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "mondo0005068_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(mondo0005068_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(mondo0005068_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Myocardial infarction (`HP_0001658`)** <a class=\"anchor\" id=\"hpo1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'HP'; node = [obo.HP_0001658]\n",
    "path_list = nx_ancestor_search(kg, node.copy(), prefix)\n",
    "hp0001658_ancestors = processes_ancestor_path_list(path_list, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(hp0001658_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in hp0001658_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "hp0001658_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(hp0001658_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(hp0001658_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "### Path-Level Characterization  <a class=\"anchor\" id=\"path-level\"></a>\n",
    "\n",
    "This section characterizes the following concept pairs:\n",
    "- [benazepril (`CHEBI_3011`) - Myocardial Infarction (`MONDO_0005068`)](#pair1)     \n",
    "- [hydrochlorothiazide (`CHEBI_5778`) - Myocardial Infarction (`MONDO_0005068`)](#pair2)  \n",
    "- [benazepril (`CHEBI_3011`) - Myocardial infarction (`HP_0001658`)](#pair3)     \n",
    "- [hydrochlorothiazide (`CHEBI_5778`) - Myocardial infarction (`HP_0001658`)](#pair4)  \n",
    "\n",
    "*Note*. All output is presented twice for each analysis, the first without any metadata/evidence and the second time, with metadata. This is done to facilitate readability.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**benazepril (`CHEBI_3011`) - Myocardial Infarction (`MONDO_0005068`)** <a class=\"anchor\" id=\"pair1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_3011, obo.MONDO_0005068))\n",
    "formats_path_information(kg, shortest_paths, path_type='shortest', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_3011, target=obo.MONDO_0005068, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=False, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**hydrochlorothiazide (`CHEBI_5778`) - Myocardial Infarction (`MONDO_0005068`)** <a class=\"anchor\" id=\"pair2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_5778, obo.MONDO_0005068))\n",
    "formats_path_information(kg, shortest_paths, path_type='shortest', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_5778, target=obo.MONDO_0005068, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=False, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**benazepril (`CHEBI_3011`) - Myocardial infarction (`HP_0001658`)** <a class=\"anchor\" id=\"pair3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_3011, obo.HP_0001658))\n",
    "formats_path_information(kg, shortest_paths, path_type='shortest', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_3011, target=obo.HP_0001658, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=False, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**hydrochlorothiazide (`CHEBI_5778`) - Myocardial infarction (`HP_0001658`)** <a class=\"anchor\" id=\"pair4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_5778, obo.HP_0001658))\n",
    "formats_path_information(kg, shortest_paths, path_type='shortest', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_5778, target=obo.HP_0001658, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=False, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg, simple_paths, path_type='simple', metadata_func=metadata_formatter, metadata_dict=metadata_dict, node_metadata=node_data_dict, verbose=True, rand=True, sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
