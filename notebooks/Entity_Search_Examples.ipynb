{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width='325' src=\"https://user-images.githubusercontent.com/8030363/161553611-51a40cf9-e348-4eff-91bd-ab03eac41dd3.png\" />\n",
    "</p>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "# Knowledge Graph Entity Search Examples\n",
    "\n",
    "***\n",
    "\n",
    "**Author:** [TJCallahan](http://tiffanycallahan.com/)  \n",
    "**GitHub Repository:** [PheKnowLator](https://github.com/callahantiff/PheKnowLator/wiki)  \n",
    "**Wiki Page:** [OWL-NETS-2.0](https://github.com/callahantiff/PheKnowLator/wiki/OWL-NETS-2.0)  \n",
    "**Release:** **[v3.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v3.0.0)**  \n",
    "  \n",
    "<br> \n",
    "\n",
    "## Purpose  \n",
    "The goal of this notebook is to explore different ways to examine relationships between different types of entities in a PheKnowLator knowledge graph.\n",
    "\n",
    "### Notebook Organization  \n",
    "- [Set-Up Environment](#set-environment)  \n",
    "- [Knowledge Graph Data](#kg-data)  \n",
    "- [Knowledge-based Characterization](#kg-characterization)  \n",
    "  - [Node-Level Characterization](#node-level)  \n",
    "  - [Path-Level Characterization](#path-level)  \n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***  \n",
    "## Set-Up Environment  <a class=\"anchor\" id=\"set-environment\"></a> \n",
    "***  \n",
    "___\n",
    "\n",
    "### Dependencies: [pkt_kg](https://pypi.org/project/pkt-kg/), [networkx](https://pypi.org/project/networkx/), [rdflib](https://pypi.org/project/rdflib/)\n",
    "\n",
    "To prepare for the tutorial we need to make sure that the all needed libraries are downloaded and imported. If you don't already have `pkt_kg`, `rdflib`, and `networkx` installed, you can extend the code chunk below to include any libraries that you need to download. In addition to downloading needed libraries, you will also need to download the specific version of each knowledge graph that you want to analyze. Each data source is briefly described in the next section.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment and run to install any required modules from notebooks/requirements.txt\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -r ../../notebooks/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if running a local version (i.e., forked from GitHub) of pkt_kg, uncomment the code below\n",
    "# import sys\n",
    "# sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import json\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "from pkt_kg.utils import *\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import RDFS\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "# create namespace for OBO ontologies\n",
    "obo = Namespace('http://purl.obolibrary.org/obo/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions \n",
    "Helper functions used only by this notebook that are needed to process and label knowledge graph node and edge entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     18,
     44,
     69
    ]
   },
   "outputs": [],
   "source": [
    "def format_path_ancestors(anc_dict: Dict, node_metadata: Dict) -> List:\n",
    "    \"\"\"Processes a dictionary of node ancestors into a list.\n",
    "\n",
    "    Args:\n",
    "        anc_dict: A dictionary where keys are ints formatted as strings and values are sets of URL strings for each\n",
    "            concept that was found at that level. The level is the distance in the hierarchy from the searched node.\n",
    "        node_metadata: A nested dictionary containing node attributes.\n",
    "\n",
    "    Returns:\n",
    "        ancestors: A nested list where each inner list contains ontology identifier strings.\n",
    "    \"\"\"\n",
    "\n",
    "    ancestors = [['{} ({})'.format(node_metadata[str(x)]['label'], x) for x in anc_dict[str(k)]]\n",
    "                 for k in sorted([int(x) for x in anc_dict.keys()])]\n",
    "\n",
    "    return ancestors\n",
    "\n",
    "\n",
    "def formats_node_information(node: URIRef, neighborhood: List, metadata_dict: Dict, verbose: bool=False) -> None:\n",
    "    \"\"\"Processes neighborhood results.\n",
    "    \n",
    "    Args:\n",
    "        node: A string containing a node URL.\n",
    "        neighborhood: A nested list of strings, where each string contains a node identifier.\n",
    "        metadata_dict: A nested dictionary containing node attributes.\n",
    "        verbose: A bool indicating whether or not node and edge metadata should be printed.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    for e, o in neighborhood:\n",
    "        spe = '\\n' if neighborhood.index([e, o]) == 0 else '\\n\\n'\n",
    "        s, s_label = str(node[0]).split('/')[-1], metadata_dict[str(node[0])]['label']\n",
    "        e_label = metadata_dict[str(e)]['label']\n",
    "        o, o_label, o_def = str(o).split('/')[-1], metadata_dict[str(o)]['label'], metadata_dict[str(o)]['description']\n",
    "        if verbose:\n",
    "            if o_def != 'None': print(spe + '>>> {} ({}) - {} - {} ({})\\n{} Definition: {}'.format(s_label, s, e_label, o_label, o, o, o_def))\n",
    "            else: print(spe + '>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "        else: print('>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "    \n",
    "    return None\n",
    "    \n",
    "\n",
    "def metadata_formatter(s: str, o: str, metadata_dict: Dict) -> None:\n",
    "    \"\"\"Function looks up edge-level metadata and prints it.\n",
    "    \n",
    "    Args:\n",
    "        s: A string containing the identifier for the subject node of a predicate or triple.\n",
    "        o: A string containing the identifier for the object node of a predicate or triple.\n",
    "        metadata_dict: A nested dictionary containing node and edge-level metadata.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s + '-reactome_' if 'R-HSA' in s else s\n",
    "    o = o + '-reactome_' if 'R-HSA' in o else o\n",
    "    \n",
    "    if s + '-' + o in metadata_dict['edges'].keys():\n",
    "        print('\\nEdge Evidence'); print(json.dumps(metadata_dict['edges'][s + '-' + o], indent=4))\n",
    "    elif o + '-' + s in metadata_dict['edges'].keys():\n",
    "         print('\\nEdge Evidence'); print(json.dumps(metadata_dict['edges'][o + '-' + s], indent=4))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def formats_path_information(kg: nx.multidigraph.MultiDiGraph, paths: List, path_type: str, metadata_func: Callable, metadata_dict: Dict, node_metadata: Dict, verbose: bool=False, rand: bool=False, sample_size: int=10) -> None:\n",
    "    \"\"\"Processes shortest and simple path results.\n",
    "    \n",
    "    Args:\n",
    "        kg: A networkx MultiDiGraph object.\n",
    "        paths: A nested list of strings, where each string contains an an entity identifier.\n",
    "        path_type: A string, either 'simple' or 'shortest' that indicates the types of paths to process.\n",
    "        metadata_func: A function that processes edge metadata.\n",
    "        metadata_dict: A nested dictionary containing node and edge-level metadata. \n",
    "        node_metadata: A nested dictionary containing node attributes.\n",
    "        verbose: A bool indicating whether or not node and edge metadata should be printed.\n",
    "        rand: A bool indicating whether or not to draw random samples from the path.\n",
    "        sample_size: An integer used when rand is True to specify the size of the random sample to draw.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    if path_type == 'shortest': \n",
    "        for i in range(0, len(paths[0]) - 1):\n",
    "            s = paths[0][i]; o = paths[0][i + 1]\n",
    "            edges = kg.get_edge_data(*(s, o)).keys()\n",
    "            for e in edges:\n",
    "                spe = '\\n' if list(edges).index(e) == 0 else '\\n\\n\\n'\n",
    "                s, s_label = str(s).split('/')[-1], node_metadata[str(s)]['label']\n",
    "                e_label = node_metadata[str(e)]['label']\n",
    "                o, o_label, o_def = str(o).split('/')[-1], node_metadata[str(o)]['label'], node_metadata[str(o)]['description']\n",
    "                if verbose:\n",
    "                    if o_def != 'None': print(spe + '>>> {} ({}) - {} - {} ({})\\n\\n{} Definition: {}'.format(s_label, s, e_label, o_label, o, o, o_def))\n",
    "                    else: print(spe + '>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "                    metadata_func(s, o, metadata_dict)\n",
    "                else: print('>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "    else:\n",
    "        if rand: paths = random.sample(paths, sample_size)\n",
    "        for path in paths:\n",
    "            print('*' * 100)\n",
    "            for i in range(0, len(path) - 1):\n",
    "                spe = '\\n' if i == 0 else '\\n\\n\\n'\n",
    "                s = path[i]; o = path[i + 1]; edges = kg.get_edge_data(*(s, o))\n",
    "                try: edges.keys()\n",
    "                except AttributeError: edges = kg.get_edge_data(*(o, s))\n",
    "                for e in edges.keys():\n",
    "                    s, s_label = str(s).split('/')[-1], node_metadata[str(s)]['label']\n",
    "                    e_label = node_metadata[str(e)]['label']\n",
    "                    o, o_label, o_def = str(o).split('/')[-1], node_metadata[str(o)]['label'], node_metadata[str(o)]['description']\n",
    "                    if verbose:\n",
    "                        if o_def != 'None': print(spe + '>>> {} ({}) - {} - {} ({})\\n\\n{} Definition: {}'.format(s_label, s, e_label, o_label, o, o, o_def))\n",
    "                        else: print(spe + '>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "                        metadata_func(s, o, metadata_dict)\n",
    "                    else: print('>>> {} ({}) - {} - {} ({})'.format(s_label, s, e_label, o_label, o))\n",
    "            print('*' * 100); print('\\n')\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## Knowledge Graph Data  <a class=\"anchor\" id=\"kg-data\"></a>\n",
    "***\n",
    "___\n",
    "\n",
    "This notebook was built using a `v3.0.2` OWL-NETS-abstracted subclass-based build with inverse relations, which is publicly available and can be downloaded using the following links:  \n",
    "- [PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle](https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle)  \n",
    "- [PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt](https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data  \n",
    "***\n",
    "\n",
    "The knowledge graph data is publicly available and downloaded from the PheKnowLator project's Google Cloud Storage Bucket: https://console.cloud.google.com/storage/browser/pheknowlator/. Data will be downloaded to a temporary directory created in the PheKnowLator root directory (`PheKnowLator/temp_directory`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook will create a temporary directory and will download data to it\n",
    "write_location = '../temp_directory/'\n",
    "if not os.path.exists(write_location): os.mkdir(write_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data to the data directory\n",
    "data_urls = [\n",
    "    'https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NetworkxMultiDiGraph.gpickle',\n",
    "    'https://storage.googleapis.com/pheknowlator/current_build/knowledge_graphs/subclass_builds/inverse_relations/owlnets/PheKnowLator_v3.0.2_full_subclass_inverseRelations_OWLNETS_NodeLabels.txt',\n",
    "    'https://www.dropbox.com/s/ev0ea6v6fu70fbl/entity_metadata_dict.pkl?dl=1'\n",
    "]\n",
    "\n",
    "for url in data_urls:\n",
    "    file_name = url.split('/')[-1] if 'entity_metadata_dict.pkl' not in url else re.sub(r'\\?.*', '', url.split('/')[-1])\n",
    "    if not os.path.exists(write_location + file_name): data_downloader(url, write_location, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "***\n",
    "\n",
    "The knowledge graph will be loaded as a `networkx` MultiDiGraph object and the node labels will be read in and converted to a dictionary to enable easy access to node labels and other relevant metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the knowledge graph\n",
    "kg = nx.read_gpickle(write_location + data_urls[0].split('/')[-1])\n",
    "print('The knowledge graph contains {} nodes and {} edges'.format(len(kg.nodes()), len(kg.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert multidigraph to undirected graph -- needed to run some of the algorithms\n",
    "undirected_kg = kg.to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Node Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in node metadata\n",
    "node_data = pd.read_csv(write_location + data_urls[1].split('/')[-1], header=0, sep=r\"\\t\", encoding=\"utf8\", engine='python', quoting=3)\n",
    "node_data['entity_uri'] = node_data['entity_uri'].str.strip('<>')  # remove angle brackets\n",
    "node_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert node data to dictionary\n",
    "node_data_dict = dict()\n",
    "for idx, row in tqdm(node_data.iterrows(), total=node_data.shape[0]):\n",
    "    node_data_dict[row['entity_uri']] = {\n",
    "        'label': row['label'],\n",
    "        'description': row['description/definition'],\n",
    "        'synonym': row['synonym']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Node and Edge Evidence\n",
    "This file is temporary while the next release is being formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = write_location + re.sub(r'\\?.*', '', data_urls[2].split('/')[-1])\n",
    "max_bytes = 2**31 - 1; input_size = os.path.getsize(filepath); bytes_in = bytearray(0)\n",
    "with open(filepath, 'rb') as f_in:\n",
    "    for _ in tqdm(range(0, input_size, max_bytes)):\n",
    "        bytes_in += f_in.read(max_bytes)\n",
    "metadata_dict = pickle.loads(bytes_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "## Knowledge-based Characterization  <a class=\"anchor\" id=\"kg-characterization\"></a>\n",
    "***\n",
    "____\n",
    "\n",
    "The goal is to use the knowledge graph to explore what we know about specific concepts as well as what we can say about pairs of concepts. Additional details are presented by comparison below:\n",
    "\n",
    "#### [Node-Level](#node-level)\n",
    " - <u>Node Ancestry</u>: Identify all ancestors for each node up to the root.\n",
    " - <u>Node Neighborhood</u>: Returns all nodes reachable from a node of interest via a single directed edge.   \n",
    "\n",
    "\n",
    "#### [Path-Level](#path-level)\n",
    "  - <u>All Shortest Paths</u>: Returns the shortest simple path, if there are multiple paths of the same length then they are all returned.\n",
    "  - <u>All Simple Paths</u>: A simple path is a path with no repeated nodes. These nodes are identified using a modified depth-first search. Given that there are a lot of these, the initial output is limited to a random draw of 10 paths of length 10 from the first 100 derived paths.\n",
    "  \n",
    "<br>\n",
    "\n",
    "**Important.** Output for the node neighborhood and simple and shortest paths are printed twice. The first time (`verbose=False`), there is minimal node and edge evidence printed. The second time (`verbose=True`), node definitions and any available evidence from the source resources used to build the edge are printed. Note that the metadata for the edges in the neighborhood will only include a definition for the nodes that are connected to each primary node of interest.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Node-Level Characterization  <a class=\"anchor\" id=\"node-level\"></a>\n",
    "***\n",
    "\n",
    "This section characterizes the following concepts:\n",
    "- [benazepril (`CHEBI_3011`)](#chebi1)  \n",
    "- [hydrochlorothiazide (`CHEBI_5778`)](#chebi2)  \n",
    "- [Acute Myocardial Infarction (`MONDO_0004781`)](#mondo1)  \n",
    "- [Myocardial infarction (`HP_0001658`)](#hpo1)\n",
    "\n",
    "*Note*. All output is presented twice for each analysis, the first without any metadata/evidence and the second time, with metadata. This is done to facilitate readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### benazepril (`CHEBI_3011`) <a class=\"anchor\" id=\"chebi1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'CHEBI'; node = [obo.CHEBI_3011]\n",
    "chebi3011_anc_dict = processes_ancestor_path_list(nx_ancestor_search(kg, node.copy(), prefix))\n",
    "chebi3011_ancestors = format_path_ancestors(chebi3011_anc_dict, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(chebi3011_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in chebi3011_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "chebi3011_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(node, chebi3011_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(node, chebi3011_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**hydrochlorothiazide (`CHEBI_5778`)** <a class=\"anchor\" id=\"chebi2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'CHEBI'; node = [obo.CHEBI_5778]\n",
    "path_list = nx_ancestor_search(kg, node.copy(), prefix)\n",
    "chebi5778_anc_dict = processes_ancestor_path_list(nx_ancestor_search(kg, node.copy(), prefix))\n",
    "chebi5778_ancestors = format_path_ancestors(chebi5778_anc_dict, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(chebi5778_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in chebi5778_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "chebi5778_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(node, chebi5778_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(node, chebi5778_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Myocardial Infarction (`MONDO_0005068`)** <a class=\"anchor\" id=\"mondo1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'MONDO'; node = [obo.MONDO_0005068]\n",
    "path_list = nx_ancestor_search(kg, node.copy(), prefix)\n",
    "mondo0005068_anc_dict = processes_ancestor_path_list(nx_ancestor_search(kg, node.copy(), prefix))\n",
    "mondo0005068_ancestors = format_path_ancestors(mondo0005068_anc_dict, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(mondo0005068_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in mondo0005068_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "mondo0005068_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(node, mondo0005068_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(node, mondo0005068_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Myocardial infarction (`HP_0001658`)** <a class=\"anchor\" id=\"hpo1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ancestors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's ancestors\n",
    "prefix = 'HP'; node = [obo.HP_0001658]\n",
    "path_list = nx_ancestor_search(kg, node.copy(), prefix)\n",
    "hp0001658_anc_dict = processes_ancestor_path_list(nx_ancestor_search(kg, node.copy(), prefix))\n",
    "hp0001658_ancestors = format_path_ancestors(hp0001658_anc_dict, node_data_dict)\n",
    "\n",
    "# print results -- nodes are ordered by seniority (higher numbers indicate closer to root)\n",
    "print('Ancestors of {}\\n'.format(node[0]))\n",
    "for level in range(len(hp0001658_ancestors)):\n",
    "    print('Level: {}'.format(str(level + 1)))\n",
    "    for v in hp0001658_ancestors[level]:\n",
    "        print('\\t- {}'.format(re.sub('http://purl.obolibrary.org/obo/', '', v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the node's neigborhood\n",
    "nodes = list(kg.neighbors(node[0]))\n",
    "neighbors = [a for b in [[[i, n] for j in [kg.get_edge_data(*(node[0], n)).keys()]\n",
    "                          for i in j] for n in nodes] for a in b]\n",
    "hp0001658_sorted_neigbors = sorted(neighbors, key=lambda x: (str(x[1]).split('/')[-1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes without definitions\n",
    "formats_node_information(node, hp0001658_sorted_neigbors, node_data_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print nodes with definitions\n",
    "formats_node_information(node, hp0001658_sorted_neigbors, node_data_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Path-Level Characterization  <a class=\"anchor\" id=\"path-level\"></a>\n",
    "\n",
    "***\n",
    "\n",
    "This section characterizes the following concept pairs:\n",
    "- [benazepril (`CHEBI_3011`) - Myocardial Infarction (`MONDO_0005068`)](#pair1)     \n",
    "- [hydrochlorothiazide (`CHEBI_5778`) - Myocardial Infarction (`MONDO_0005068`)](#pair2)  \n",
    "- [benazepril (`CHEBI_3011`) - Myocardial infarction (`HP_0001658`)](#pair3)     \n",
    "- [hydrochlorothiazide (`CHEBI_5778`) - Myocardial infarction (`HP_0001658`)](#pair4)  \n",
    "\n",
    "*Note*. All output is presented twice for each analysis, the first without any metadata/evidence and the second time, with metadata. This is done to facilitate readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**benazepril (`CHEBI_3011`) - Myocardial Infarction (`MONDO_0005068`)** <a class=\"anchor\" id=\"pair1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_3011, obo.MONDO_0005068))\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=shortest_paths,\n",
    "                         path_type='shortest',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_3011, target=obo.MONDO_0005068, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=False,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=True,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**hydrochlorothiazide (`CHEBI_5778`) - Myocardial Infarction (`MONDO_0005068`)** <a class=\"anchor\" id=\"pair2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_5778, obo.MONDO_0005068))\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=shortest_paths,\n",
    "                         path_type='shortest',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_5778, target=obo.MONDO_0005068, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=False,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=True,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**benazepril (`CHEBI_3011`) - Myocardial infarction (`HP_0001658`)** <a class=\"anchor\" id=\"pair3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_3011, obo.HP_0001658))\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=shortest_paths,\n",
    "                         path_type='shortest',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_3011, target=obo.HP_0001658, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=False,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=True,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**hydrochlorothiazide (`CHEBI_5778`) - Myocardial infarction (`HP_0001658`)** <a class=\"anchor\" id=\"pair4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Shortest Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at all shortest paths between the nodes in pair\n",
    "shortest_paths = list(nx.all_shortest_paths(kg, obo.CHEBI_5778, obo.HP_0001658))\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=shortest_paths,\n",
    "                         path_type='shortest',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Paths*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all simple paths between the nodes in pair\n",
    "simple_paths = []; counter = 0\n",
    "for path in tqdm(nx.all_simple_paths(undirected_kg, source=obo.CHEBI_5778, target=obo.HP_0001658, cutoff=10)):\n",
    "    simple_paths += [path]\n",
    "    if counter == 100: break\n",
    "    else: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- without definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=False,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print path information -- with definitions and metadata\n",
    "formats_path_information(kg=kg,\n",
    "                         paths=simple_paths,\n",
    "                         path_type='simple',\n",
    "                         metadata_func=metadata_formatter,\n",
    "                         metadata_dict=metadata_dict,\n",
    "                         node_metadata=node_data_dict,\n",
    "                         verbose=True,\n",
    "                         rand=True,\n",
    "                         sample_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "This Notebook is part of the [**PheKnowLator Ecosystem**](https://zenodo.org/communities/pheknowlator-ecosystem/edit/)\n",
    "\n",
    "```\n",
    "@misc{callahan_tj_2019_3401437,\n",
    "  author       = {Callahan, TJ},\n",
    "  title        = {PheKnowLator},\n",
    "  month        = mar,\n",
    "  year         = 2019,\n",
    "  doi          = {10.5281/zenodo.3401437},\n",
    "  url          = {https://doi.org/10.5281/zenodo.3401437}\n",
    "}\n",
    "```\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
